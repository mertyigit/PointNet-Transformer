{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visual Transformer 2D**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "from glob import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from torchmetrics.classification import MulticlassMatthewsCorrCoef\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import kl_div\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import open3d as o3\n",
    "import math\n",
    "import yaml\n",
    "import argparse\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "sys.path.append('../')\n",
    "from src.models.VisualTransformerEncoder import *\n",
    "from src.models.VisualTransformerDecoder import *\n",
    "from src.models.MultiHeadAttentionBlock import *\n",
    "from src.models.VisualTransformerGenerator import *\n",
    "from src.utils import features, utils\n",
    "from src.data.dataset import DataMNIST, DataMNISTGen\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP for supressing pytorch user warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is build: True\n",
      "MPS Availability: True\n",
      "Device is set to :mps\n"
     ]
    }
   ],
   "source": [
    "print('MPS is build: {}'.format(torch.backends.mps.is_built()))\n",
    "print('MPS Availability: {}'.format(torch.backends.mps.is_available()))\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'mps'\n",
    "print('Device is set to :{}'.format(DEVICE))\n",
    "torch.seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config/config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60000it [00:13, 4378.66it/s]\n",
      "10000it [00:03, 2880.95it/s]\n"
     ]
    }
   ],
   "source": [
    "data = DataMNISTGen(**config[\"data_parameters\"])\n",
    "data.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = data.train_dataloader()\n",
    "val_dataloader = data.val_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRE & POST PROCESSING SCRIPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TensorToImageGrid(images_batch, rows, cols):\n",
    "    grid = torchvision.utils.make_grid(images_batch, nrow=cols)\n",
    "    grid = grid.permute(1, 2, 0).cpu().numpy()\n",
    "    plt.figure(figsize=(cols, rows))\n",
    "    plt.imshow(grid, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    return plt.show()\n",
    "\n",
    "def TensorToImage(image):\n",
    "    plt.figure(figsize = (2, 2))\n",
    "    plt.imshow(image.numpy(), cmap='gray')\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 148/3750 [00:49<20:29,  2.93it/s]"
     ]
    }
   ],
   "source": [
    "n_patches = 7\n",
    "num_layers = 4\n",
    "hidden_d = 128\n",
    "n_heads = 8\n",
    "d_ff = 512\n",
    "dropout = 0.1\n",
    "learning_rate = 0.0001\n",
    "\n",
    "transformer = Transformer(hidden_d, n_heads, num_layers, d_ff, dropout, n_patches).to(DEVICE)\n",
    "criterion = nn.MSELoss().to(DEVICE)\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=learning_rate, eps=1e-9)\n",
    "transformer.train()\n",
    "\n",
    "\n",
    "for epoch in range(1):\n",
    "    loss_epoch = []\n",
    "    n=0\n",
    "    for images, y in tqdm(train_dataloader):\n",
    "        #images, y = batch\n",
    "        #print(batch)\n",
    "        images = images.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = transformer(images)\n",
    "        loss = criterion(y, output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch.append(loss.detach().cpu().item()) \n",
    "        #torch.mps.empty_cache()\n",
    "    \n",
    "    print(\"Epoch: {}; Loss: {}\".format(epoch+1, np.mean(loss_epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_ref, images_gen = next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.eval()\n",
    "N=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TensorToImage(transformer(images_ref)[N].squeeze().detach().cpu()), TensorToImage(images_gen[N].squeeze().detach().cpu()), TensorToImage(images_ref[N].squeeze().detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c3515861ec4313dacaa20b0eec5bf326e6557b6589b7b6a4fe3c8baa566747d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
